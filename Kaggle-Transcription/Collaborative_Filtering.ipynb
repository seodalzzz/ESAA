{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMxxdzdwr0bRQ2Hx1xGO6g6"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Collaborative filtering\n",
        "https://realpython.com/build-recommendation-engine-collaborative-filtering/\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "yQv3n06cF3Mm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.What is Collaborative Filtering?"
      ],
      "metadata": {
        "id": "kuIJBOafF7Fn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* It works by searching a large group of people and finding a smaller set of users with tastes similar to a particular user. It looks at the items they like and combines them to create a ranked list of suggestions.\n",
        "\n",
        "* They are many ways to decide which users are similar and combine their choices to create a list of recommendations."
      ],
      "metadata": {
        "id": "1zdi8FSTGA7Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.The Dataset\n",
        "\n",
        "* Set of Items / Set of Users\n",
        "\n",
        "* Reaction\n",
        "  * explicit - rating on a scale of 1 to 5, likes or dislikes\n",
        "  * implicit - viewing an item, adding it to a wish list, the time spent on an article\n",
        "\n",
        "* item-user matrix (u,i)\n",
        "  * row - ratings given by a user\n",
        "  * column - ratings received by an item\n",
        "\n",
        "* In most cases, the cells in the matrix are empty, as users only rate a few items.\n",
        "  * sparse : a matrix with mostly empty cells\n",
        "  * dense : a matrix with mostly filled cells\n",
        "\n",
        "* data sources : https://github.com/caserec/Datasets-for-Recommender-Systems\n",
        "\n",
        "* MovieLens 100K dataset\n",
        "  * 100,000 ratings given by 943 users for 1682 movies, with each user having rated at least 20 movies\n",
        "  * https://grouplens.org/datasets/movielens/100k/\n",
        "  * The ones that are of interest are the following\n",
        "    * u.item : the list of movies\n",
        "    * u.data : the list of ratings given by users\n"
      ],
      "metadata": {
        "id": "VlxjEUx2GY8V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3.Steps Involved in Colaborative Filtering"
      ],
      "metadata": {
        "id": "9jRD41TEK9wi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1) Find Similar users or items\n",
        "  * How do you determine which users or items are similar to one another?"
      ],
      "metadata": {
        "id": "H7-nQ-hRLFAU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  * Collaborative filtering is a family of algorithms where there are multiple ways to find similar users or items and multiple ways to calculate rating based on ratings of similar users.\n",
        "  * One important thing to keep in mind is that in an approach based purely on collaborative filtering, the similarity is calculated only on the basis of the rating(explicit or implicit) a user gives to an item. (NOT factors like age of users, genre of the movie etc.)\n"
      ],
      "metadata": {
        "id": "5y8Akrw7Lq7H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2) Predict ratings of the items that are not yet rated by a user\n",
        "  * Given that you know which users are similar, how do you determine the rating that a user would give to an item bases on the ratings of similar users?\n",
        "  * How do you measure the accuracy of the ratings you calculate?\n",
        "    * multiple answers, which includes error calculation techniques that can be used in many places (like RMSE,MAE...)"
      ],
      "metadata": {
        "id": "c2XPjWV5LL32"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4.Memory Based\n"
      ],
      "metadata": {
        "id": "bNvX4ov6NYXn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find the rating **R** that a user **U** would give to an item **I**, the approach includes\n",
        "  * Finding users similar to **U** who have rated the item **I**\n",
        "  * Caculating the rating **R** based the ratings of users found in the previous step"
      ],
      "metadata": {
        "id": "UZRF9WKjN3Tm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1) How to Find Similar Users on the Basis of Ratings"
      ],
      "metadata": {
        "id": "hSxukWkjOeQI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To understand the concept of similarity, let's create a simple dataset first. The data includes 4 users A,B,C, and D, who have rated two movies. The ratings are stored in lists, and each list contains two numbers indicating the ratng of each movie.\n",
        "  * Ratings by A are [1.0,2.0]\n",
        "  * Ratings by B are [2.0,4.0]\n",
        "  * Ratings by C are [2.5,4.0]\n",
        "  * Ratings by D are [4.5,5.0]\n"
      ],
      "metadata": {
        "id": "dzrokzZdPDlb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_V7AfXzIFYnr"
      },
      "outputs": [],
      "source": [
        "from scipy import spatial\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "a=[1,2]\n",
        "b=[2,4]\n",
        "c=[2.5,4.0]\n",
        "d=[4.5,5.0]\n",
        "\n",
        "ratings=[a,b,c,d]\n",
        "ratings=pd.DataFrame(ratings)\n",
        "ratings.columns=['movie1','movie2']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(x='movie1',y='movie2',data=ratings)\n",
        "plt.xlim(0,6)\n",
        "plt.ylim(0,6)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "a2iKhVHyQK_u",
        "outputId": "2c14cf1f-3723-4744-8dec-92417b7987ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Looking at the distance between the points to estimate similarity\n",
        "  * Euclidean distance"
      ],
      "metadata": {
        "id": "1rR7XOAkR6w5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(spatial.distance.euclidean(c,a))\n",
        "print(spatial.distance.euclidean(c,b))\n",
        "print(spatial.distance.euclidean(c,d))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6fm8pnIRqJG",
        "outputId": "40e1478d-8431-4b4f-814c-88ce9ebdc2c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5\n",
            "0.5\n",
            "2.23606797749979\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "> ratings of C are closest to those of B\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yp4LqyVxSR2J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You could say C is closer to D in terms of distance. But looking at the rankings, it would seem that the choices of C would align with that of A more than D because both A and C like the second movie almost twice as much as they like the first movie, but D likes both of the moveis equally.\n",
        " So, what can you use to identify such patterns that Euclidean distance cannot? Can the angle between the lines joining the points to the origin be used to make a decision? You can take a look at the angle between the lines joining the origin of the graph to the respective points as shown."
      ],
      "metadata": {
        "id": "OODykKuVSz4k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the angle between the lines is increased, then the similarity decreases, and if the angle is zero, then the users are very similar.\n",
        "\n",
        "To calculate similarity using angle, you need a function that returns a higher similarity or smaller distance for a lower angle and a lower similarity or larger distance for a highter angle. The cosine of an angle is a function that decreases from 1 to -1 as the angle increases from 0 to 180.\n",
        "\n",
        "scipy has a function that calculates the cosine distance of vectors. It returns a higher value for higher angle.\n",
        "\n"
      ],
      "metadata": {
        "id": "8SlPIo5jdu4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import spatial\n",
        "\n",
        "a=[1,2]\n",
        "b=[2,4]\n",
        "c=[2.5,4.0]\n",
        "d=[4.5,5.0]\n",
        "\n",
        "print(spatial.distance.cosine(c,a))\n",
        "print(spatial.distance.cosine(c,b))\n",
        "print(spatial.distance.cosine(c,d))\n",
        "print(spatial.distance.cosine(a,b))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdnBjKC2edyo",
        "outputId": "4405b013-ed90-4edb-ccc6-2fe5532e6649"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.004504527406047898\n",
            "0.004504527406047898\n",
            "0.015137225946083022\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> the lower angle between the vectors of C and A gives a lower cosine distance value."
      ],
      "metadata": {
        "id": "SAWrJOOhe5VR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that users A and B are considered absolutely similar in the cosine similarity metric despite having different ratings. The users like the user A are what you can call tough raters. They gives out ratings lower thatn the average, but their list would be similar to the Average raters like B."
      ],
      "metadata": {
        "id": "7K8Z-RhqfU8x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To factor in such individual user preferences, you will need to bring all users to the same level by removing their biases.\n",
        "\n",
        "Subtracting the average rating given by that user to all items from each item rated by that user. >> You have Changed the value of the average rating given by every user to 0."
      ],
      "metadata": {
        "id": "5Vx6QM-8f2Yf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Centered cosine\n",
        "  * The cosine of the angle between the adjusted vectors\n",
        "  * Normally used when there are a lot of missing values in the vectors, and you need to place a common value to fill up the missing values."
      ],
      "metadata": {
        "id": "sIRG_8j7ge_s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2)How to Calculate the Ratings"
      ],
      "metadata": {
        "id": "dO5lRvP9jQRK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After you have determined a list of users similar to a user **U**, you need to calculate the rating **R** that **U** would give to a certain itel **I**.\n",
        "\n",
        "You can predict that a user's rating **R** for an item **I** will be close to the average of the ratings given to **I** by the top 5 or top 10 users most similar to **U**.\n",
        "\n",
        "There will be situations where the n similar users that you found are not equally similar to the target user **U**.\n",
        "  * ex. Top of 3 are very similar, rest might not be as similar to **U** as the top 3.\n",
        "  * need weighted average\n",
        "\n",
        "In the weighted average approach\n",
        "  * multiply each rating by a similarity factor => add weights to the ratings\n",
        "  * similarity factor should be the inverse of the distance (less distance implies higher similarity)\n",
        "    * ex. cosine similarity factor = 1 - cosine distance\n",
        "\n",
        "With the similarity factor **S** for each user similar to the target user **U**, you can calculate the weighted average using this formula.\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "  * The final predicted rating by user **U** will be equal to the sum of the weighted ratings divided by the sum of the weightes."
      ],
      "metadata": {
        "id": "gaGtgBa_lwiq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3)User-Based vs Item Based Collaborative Filtering"
      ],
      "metadata": {
        "id": "ceuZ6qLppNNs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####(1)User-based\n",
        "  * For a user **U**, with a set of similar users determined based on rating vectors consisting of given item ratings, the rating for an item **I**, which hasn't been rated, is found by picking out N users from the similarity list who have rated the item **I** and calculating the rating based on these N ratings.\n"
      ],
      "metadata": {
        "id": "6QL5clalUV_0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####(2)Item-based\n",
        "  * For an item **I**, with a set of similar items determined based on rating vectors consisting of received user ratings, the rating by a user **U**, who hasn't rated it, is found by picking out N items from the similarity list that have been rated by **U** and calculating the rating based on these N ratings.\n",
        "  * It is effective because usually, the average rating received by an item doesn't change as quickly as the average rating given by a user to different items.\n",
        "  * better than user-bases when ratings matrix is sparse\n",
        "  * performs poorly for datasets with browsinig or entertainment related items such as MovieLens, where the recommendations it gives out seem very obvious to the target users."
      ],
      "metadata": {
        "id": "ZSZS8BSnVAaR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5.Model Based\n",
        "Model Based approach involve a step to reduce or compress the large but sparse user-item matrix."
      ],
      "metadata": {
        "id": "KWvMUdSpX5oo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1)Dimensionality Reduction\n",
        "User-item matrix : 2 dimensions - (# of Users, # of items)\n",
        "\n",
        "If the matrix is mostly empty, reducing dimensions can improve the performance of the algorithm in terms of both space and time. > using matrix factorization, autoencoders ..."
      ],
      "metadata": {
        "id": "C-41usWpY3fB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####(1)Matrix factorization\n",
        "  * Matrix factorization can be seen as breaking down a large matrix into a product of smaller ones.\n",
        "  * **A** (mxn) = **X** (mxp) x **Y** (pxn)\n",
        "  * The reduced matrices actually represent the users and items individually. The **m** rows in the X represent the **m** users, and the **p** columns tell you about the features or characteristics of the users.\n",
        "  * The columns in the user matrix and the two rows in the item matrix are called latent factors and are an indication of hidden characteristics about the users or the items.\n",
        "  * Possible interpretation of the factorization\n",
        "    * Assume that in a user vector (u,v), u represents how much a user likes the Horror genre, and v represents how much they like the Romance genre\n",
        "    * The user vector (2,-1) thus represents a user who likes horror movies and rates them positively and dislikes movies that have romance and rates them negatively.\n",
        "    * Assume that in an item vector (i,j), i represents how much a movie belongs to the Horror genre, and j represents how much that movie belongs to the Romance genre\n",
        "    * The movie (2.5,1) has a Horror rating of 2.5 and a Romance rating of 1. Multiplying it by the user vector using matrix multiplication rules gives you (2x2.5)+(-1x1)=4 \n",
        "    * So, the movie belonged to the Horror genre, and the user could have rated it 5, but the slight inclusion of Romance caused the final rating to drop to 4.\n",
        "  \n",
        "  * The factor matrices can provide such insights about users and items, but in reality they are usually much more complex. The number of such factors can be anything from one to hundreds or even thousands. This number is one of the things that need to be optimized during the training of the model.\n",
        "  * In real analysis, latent factors need not be analyzed too much. These are patterns in the data that will play their part automatically whether you decipher their underlying meaning or not.\n",
        "  * The number of latent factors affects the recommendations in a manner where the greater the number of factors, the more personalized the recommendations become. But too many factors can lead to overfitting in the model."
      ],
      "metadata": {
        "id": "Yqv70sCDZjpV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2) Algorithms for Matrix Facotrization\n",
        "  * SVD (Singular Value Decomposition)\n",
        "  * PCA\n",
        "  * NMF\n",
        "  * Autoencoders\n",
        "    * can also be used for dimensionality reduction in case you want to use Neural Networks\n",
        "  * cf) Mining of Massive Datasets : http://www.mmds.org/"
      ],
      "metadata": {
        "id": "vnTk6In3hayh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6.Using Python to Build Recommenders"
      ],
      "metadata": {
        "id": "SwPVhMg3ifnw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Surprise\n",
        "  * Surprise is a Python SciKit that comes with various recommender algorithms and similarity metrics to make it easy to build and analyze recommenders\n",
        "\n",
        "* Surpirse Modules and classes\n",
        "  * Dataset (Module) : load data\n",
        "    * Dataset.load_builtin()\n",
        "    * Dataset.load_from_file()\n",
        "    * Dataset.load_from_df()\n",
        "  * Reader (Class) : parse a file containing ratings\n",
        "    * The default format in which it accepts data is that each rating is stored in a separate line in the order user item rating. This order and the separator can be configured using parameters:\n",
        "      * line_format : string that stored the order of the data with field names separated by a space, as in \"item user rating\"\n",
        "      * sep : specify separator between fields, such as ','\n",
        "      * rating_scale : specify the rating scale. default : (1,5)\n",
        "      * skip_lines : indicated the number of lines to skip at the beginning of the file. The default is 0.\n",
        "      "
      ],
      "metadata": {
        "id": "rZNlM9kdi2HB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load_data.py\n",
        "\n",
        "import pandas as pd\n",
        "import surprise import Dataset\n",
        "import surprise import Reader\n",
        "\n",
        "# This is the same data that was plotted for similarity earlier\n",
        "# with one new user \"E\" who has rated only movie 1\n",
        "ratings_dict={\n",
        "    \"item\":[1,2,1,2,1,2,1,2,1],\n",
        "    \"user\":['A','A','B','B','C','C','D','D','E'],\n",
        "    \"rating\":[1,2,2,4,2.5,4,4.5,5,3]\n",
        "}\n",
        "\n",
        "df=pd.DataFrame(ratings_dict)\n",
        "reader=Reader(rating_scale=(1,5))\n",
        "\n",
        "#Loads Pandas dataframe\n",
        "data=Dataset.load_from_df(df[[\"user\",\"item\",\"rating\"]],reader)\n",
        "#Loads the builtin Movielnes-100k data\n",
        "movielens=Dataset.load_builtin('ml-100k')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "0i-eQpvJjFi2",
        "outputId": "f930e7bb-af32-4fc3-c8d6-84baf4872925"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-481aef798637>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    import surprise import Dataset\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In above program, the data is stored in a dictionary that is loaded into a Pandas dataframe and then into a Dataset object from Surprise."
      ],
      "metadata": {
        "id": "W9WQe6KGoSZu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1)Algorithms Based on K-Nearest Neighbours(k-NN)\n",
        "* For the memory-based approaches\n",
        "* very close to the centered cosine similarity formula\n",
        "* available in Surprise as KNNWithMeans\n",
        "* To find the similarity, you simply have to configure the function by passing a dictionary as an argument to the recommender function.\n",
        "  * name : contains the similarity metric to use. - cosine, msd,pearson,pearson_baseline\n",
        "  * user_based : bollean that tells whether the approach will be user-based or item-based / default : True (=user-based)\n",
        "  * min_support : minimum number of common items needed between users to consider them for similarity. For the item-based approach, this corresponds to the minimum number of common users for two items."
      ],
      "metadata": {
        "id": "8PJaguZOprC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#recommender.py\n",
        "\n",
        "from surprise import KNNWithMeans\n",
        "\n",
        "#To use item-based cosine similarity\n",
        "sim_options={\n",
        "    \"name\":\"cosine\"\n",
        "    \"user_based\":False, #Compute similarities between items\n",
        "}\n",
        "\n",
        "algo=KNNWithMeans(sim_options=sim_options)"
      ],
      "metadata": {
        "id": "27-YGOORvZJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> using cosine similarity / similar items using the item-based approach"
      ],
      "metadata": {
        "id": "VQ6L1czKvufz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Trainset\n",
        "  * Trainset is built using the same data but contains more information about the data\n",
        "  * You can create it either by using the entire data or a part of the data\n",
        "  * You can also divide the data into folds where some of the data will be used for training and some for testing.\n",
        "  "
      ],
      "metadata": {
        "id": "IRntVY_1wDl4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example to find out how the user E would rate the movie 2:\n",
        "from load_data import data\n",
        "from recommender import algo\n",
        "\n",
        "trainingSet=data.build_full_trainset()\n",
        "\n",
        "algo.fit(trainingSet)\n",
        "\n",
        "prediction=algo.predict('E',2)\n",
        "prediction.est"
      ],
      "metadata": {
        "id": "5blhoXXbwhao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> The algorithm predicted that the user E would rate the movie 4.15, which could be high enough to be shown as a recommendation."
      ],
      "metadata": {
        "id": "e_SfKxkww6_m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2)Tuning the Algorithm Parameters\n",
        "* Surprise provides a GridSearchCV class analogous to GridSearchCV from scikit-learn.\n",
        "* With a dict of all parameters, GridSearchCV tries all the combinations of parameters and reports the best parameters for any accuracy measure\n"
      ],
      "metadata": {
        "id": "4FMBbzlkxoKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check which similarity metric works best for your data in memory-based approaches\n",
        "from surprise import KNNWithMeans\n",
        "from surprise import Dataset\n",
        "from surprise.model_selection import GridSearchCV\n",
        "\n",
        "data=Dataset.load_builtin(\"ml-100k\")\n",
        "sim_options={\n",
        "    \"name\":[\"msd\",\"cosine\"],\n",
        "    \"min_support\":[3,4,5],\n",
        "    \"user_based\":[False, True]\n",
        "}\n",
        "\n",
        "param_grid={\"sim_options\":sim_options}\n",
        "\n",
        "gs=GridSearchCV(KNNWithMeans, param_grid, measures=[\"rmse\",\"mae\"],cv=3)\n",
        "gs.fit(data)\n",
        "\n",
        "print(gs.best_score[\"rmse\"])\n",
        "print(gs.best_params[\"rmse\"])"
      ],
      "metadata": {
        "id": "-AeIqYOwySwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Similarly, for model-based approaches, we can use Surprise to check which values for the following factors work best:\n",
        "  * n_epochs : # of iterations of SGD, which is basically an iterative method used in statistics to minimize a function\n",
        "  * lr_all : learning rate for all parameters, which is a parameter that decides how much the parameters are adjusted in each iteration\n",
        "  * reg_all : regularization term for all parameters, which is a penalty term added to prevent overfitting"
      ],
      "metadata": {
        "id": "KmHi3YoZzKhe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check the best values for the SVD algorithm\n",
        "\n",
        "from surprise import SVD\n",
        "from surprise import Dataset\n",
        "from surprise.model_selection import GridSearchCV\n",
        "\n",
        "data=Dataset.load_builtin(\"ml-100k\")\n",
        "\n",
        "param_grid={\n",
        "    \"n_epochs\":[5,10],\n",
        "    \"lr_all\":[0.002,0.005],\n",
        "    \"reg_all\":[0.4,0.6]\n",
        "}\n",
        "\n",
        "gs=GridSearchCV(SVD, param_grid, measures=[\"rmse\",\"mae\"],cv=3)\n",
        "\n",
        "gs.fit(data)\n",
        "\n",
        "print(gs.best_score[\"rmse\"])\n",
        "print(gs.best_params[\"rmse\"])"
      ],
      "metadata": {
        "id": "30H5dpXIzxyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Other matrix factorization based algorithms available in Surprise are SVD++ and NMF\n"
      ],
      "metadata": {
        "id": "sHMwzvby0Ztj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##7.When Can Collaborative Filtering Be Used?\n",
        "  * Collaborative filtering doesn't require features about the items or users to be known. It is suited for a set of different types of items.\n",
        "    * But In a set of similar items such as that of a bookstore, though, known features like writers and genres can be useful and might benefit from content-based or hybrid approaches\n",
        "  * Collaborative filtering can help recommenders to not overspecialize in a user's profile and recommend items that are completely different from what they have seen before.\n",
        "\n",
        "* Some of challenges that are faced while using Collaborative filtering\n",
        "  * Colalborative filtering can lead to some problems like cold start for new items that are added to the list. Until someone rates them, they don't get recommended.\n",
        "  * Data sparsity can affect the quality of user-based recommenders and also add to the cold start problem mentioned above.\n",
        "  * Scaling can be a challenge for growing datasets as the complexity can become too large. Item-based recommenders are faster than user-based when the dataset is large.\n",
        "  * With a straightforward implementation, you might observe that the recommendations tend to be already popular, and the items from the long tail section might get ignored.\n",
        "\n",
        "* Hybrid Recommender\n",
        "  * The benefits of multiple algorithms working together or in a pipeline can help you set up more accurate recommenders.\n"
      ],
      "metadata": {
        "id": "xROMLOby0n5p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##8.Conclusion\n",
        "\n",
        "* calculations go into a collaborative-filtering type recommender\n",
        "* Even if it does not seem to fit your data with high accuracy, some of the use cases discussed might help you plan thing sin a hybrid way for the long term."
      ],
      "metadata": {
        "id": "kvOhB1YN3Jn1"
      }
    }
  ]
}